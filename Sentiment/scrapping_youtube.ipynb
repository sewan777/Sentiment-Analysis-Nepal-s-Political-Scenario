{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import googleapiclient.discovery\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# YouTube API setup\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "DEVELOPER_KEY = \"AIzaSyAVTScqtDxBt_G5CDxoxqoRnRvYVBzFOHU\"\n",
    "\n",
    "youtube = googleapiclient.discovery.build(\n",
    "    api_service_name, api_version, developerKey=DEVELOPER_KEY\n",
    ")\n",
    "\n",
    "# Step 1: Search for videos on a topic\n",
    "search_request = youtube.search().list(\n",
    "    part=\"snippet\",\n",
    "    q=\"Balen Shah\",  # Replace with your topic\n",
    "    type=\"video\",\n",
    "    maxResults=50  # Set maxResults to 50 (the limit)\n",
    ")\n",
    "search_response = search_request.execute()\n",
    "video_ids = [item['id']['videoId'] for item in search_response['items']]\n",
    "\n",
    "# Pagination for videos (in case there are more than 50 results)\n",
    "nextPageToken = search_response.get('nextPageToken')\n",
    "while nextPageToken:\n",
    "    search_request = youtube.search().list(\n",
    "        part=\"snippet\",\n",
    "        q=\"Balen Shah\",\n",
    "        type=\"video\",\n",
    "        maxResults=50,\n",
    "        pageToken=nextPageToken\n",
    "    )\n",
    "    search_response = search_request.execute()\n",
    "    video_ids.extend([item['id']['videoId'] for item in search_response['items']])\n",
    "    nextPageToken = search_response.get('nextPageToken')\n",
    "\n",
    "# Step 2: Fetch comments for each video\n",
    "all_comments = []\n",
    "nextPageToken = None  # Initialize for pagination\n",
    "\n",
    "for video_id in video_ids:\n",
    "    try:\n",
    "        for _ in range(5):  \n",
    "            request = youtube.commentThreads().list(\n",
    "                part=\"snippet\",\n",
    "                videoId=video_id,\n",
    "                maxResults=100,  # Max 100 per request\n",
    "                pageToken=nextPageToken\n",
    "            )\n",
    "            response = request.execute()\n",
    "\n",
    "            for item in response['items']:\n",
    "                comment = item['snippet']['topLevelComment']['snippet']\n",
    "                all_comments.append([\n",
    "                    video_id,\n",
    "                    comment['authorDisplayName'],\n",
    "                    comment['publishedAt'],\n",
    "                    comment['likeCount'],\n",
    "                    comment['textDisplay']\n",
    "                ])\n",
    "\n",
    "            # Handle pagination for comments\n",
    "            nextPageToken = response.get('nextPageToken')\n",
    "            if not nextPageToken:\n",
    "                break\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching comments for video {video_id}: {e}\")\n",
    "\n",
    "# Step 3: Organize data\n",
    "df = pd.DataFrame(all_comments, columns=['video_id', 'author', 'published_at', 'like_count', 'text'])\n",
    "\n",
    "# Convert 'published_at' to datetime and remove timezone info\n",
    "df['published_at'] = pd.to_datetime(df['published_at'], errors='coerce').dt.tz_localize(None)\n",
    "\n",
    "# Define date ranges (now timezone-naive)\n",
    "range1_start = datetime(2021, 5, 1)\n",
    "range1_end = datetime(2022, 5, 31)\n",
    "range2_start = datetime(2023, 5, 1)\n",
    "range2_end = datetime(2024, 5, 31)\n",
    "\n",
    "# Filter comments by date ranges\n",
    "df_range1 = df[(df['published_at'] >= range1_start) & (df['published_at'] <= range1_end)]\n",
    "df_range2 = df[(df['published_at'] >= range2_start) & (df['published_at'] <= range2_end)]\n",
    "\n",
    "# Balance the data\n",
    "min_size = min(len(df_range1), len(df_range2))  # Ensure equal number of comments\n",
    "df_range1 = df_range1.sample(n=min_size, random_state=42)\n",
    "df_range2 = df_range2.sample(n=min_size, random_state=42)\n",
    "\n",
    "# Save to CSV\n",
    "df_range1.to_csv('/content/drive/My Drive/Youtube Comments/comments_2021_2022.csv', index=False)\n",
    "df_range2.to_csv('/content/drive/My Drive/Youtube Comments/comments_2023_2024.csv', index=False)\n",
    "\n",
    "print(\"Balanced datasets saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
