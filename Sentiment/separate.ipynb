{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To merge before and after dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1  = pd.read_csv(\"Balen_election_month\")\n",
    "df2 = pd.read_csv(\"Balen_after\")\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a 'time_period' column to differentiate datasets\n",
    "df1['time_period'] = 'before_election'\n",
    "df2['time_period'] = 'after_election'\n",
    "\n",
    "# Combine the datasets\n",
    "df_combined = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Check for inconsistencies in column names or data types\n",
    "print(df_combined.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To detect the language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "import re\n",
    "\n",
    "def classify_script_langdetect(text):\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "        \n",
    "        if lang == 'en':\n",
    "            return 'English'\n",
    "        elif lang == 'ne':  # Nepali\n",
    "            # Check if it's Romanized Nepali (contains English characters)\n",
    "            if re.search(r'[a-zA-Z]', text):\n",
    "                return 'Romanized Nepali'\n",
    "            else:\n",
    "                return 'Devanagari'\n",
    "        else:\n",
    "            # If language detection fails or it's an unknown language, classify as Romanized Nepali\n",
    "            return 'Romanized Nepali'\n",
    "    except Exception as e:\n",
    "        # If there is an exception (e.g., language detection fails), classify as Romanized Nepali\n",
    "        return 'Romanized Nepali'\n",
    "\n",
    "# Apply the function to your DataFrame\n",
    "df_combined['script'] = df_combined['text'].apply(classify_script_langdetect)\n",
    "\n",
    "# Check the result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To separate into 3 different dataframe for english, romanized nepali and devanagari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_english = df_combined[df_combined['script'] == 'English']\n",
    "df_romanized_nepali = df_combined[df_combined['script'] == 'Romanized Nepali']\n",
    "df_devanagari = df_combined[df_combined['script'] == 'Devanagari']\n",
    "df_devanagari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To transliterate romanized nepali into devanagari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from deep_translator import GoogleTranslator\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Load your CSV into a DataFrame\n",
    "df = df_romanized_nepali  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to transliterate Romanized Nepali to Devanagari\n",
    "def roman_to_devanagari(text):\n",
    "    try:\n",
    "        # Handle empty or null text\n",
    "        if not text or pd.isna(text):\n",
    "            return \"\"  # Return empty string if the text is empty or NaN\n",
    "        \n",
    "        # Remove emojis and special characters that may cause issues with the translation\n",
    "        # This will match most common emoji patterns\n",
    "        text = re.sub(r'[^\\x00-\\x7F]+', '', text)  # Remove non-ASCII characters (emojis, symbols)\n",
    "\n",
    "        # Transliterate Romanized Nepali to Devanagari using Google Translator\n",
    "        return GoogleTranslator(source='en', target='ne').translate(text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during translation: {e}\")\n",
    "        return \"\"  # Return an empty string if there's an error\n",
    "\n",
    "# Function to estimate time for batch processing\n",
    "def estimate_translation_time(df, batch_size=10):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Apply transliteration to a small batch of rows\n",
    "    df_batch = df.head(batch_size)\n",
    "    df_batch['text_devanagari'] = df_batch['text'].apply(roman_to_devanagari)\n",
    "    \n",
    "    # Time taken for this batch\n",
    "    batch_time = time.time() - start_time\n",
    "    print(f\"Time taken for {batch_size} rows: {batch_time:.2f} seconds\")\n",
    "    \n",
    "    # Estimate total time for all rows\n",
    "    total_rows = len(df)\n",
    "    estimated_time = (total_rows / batch_size) * batch_time  # Estimated time for all rows\n",
    "    estimated_minutes = estimated_time / 60  # Convert to minutes\n",
    "    print(f\"Estimated time for {total_rows} rows: {estimated_minutes:.2f} minutes\")\n",
    "    \n",
    "    return df_batch, estimated_time\n",
    "\n",
    "# Test the function with a batch of 5 rows\n",
    "df_batch, estimated_time = estimate_translation_time(df, batch_size=5)\n",
    "\n",
    "# Apply transliteration to the entire DataFrame\n",
    "df['text_devanagari'] = df['text'].apply(roman_to_devanagari)\n",
    "\n",
    "# Optionally, save the updated DataFrame back to a CSV file\n",
    "# df.to_csv('transliterated_output.csv', index=False)\n",
    "\n",
    "# Check the result\n",
    "print(df[['text', 'text_devanagari']].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
